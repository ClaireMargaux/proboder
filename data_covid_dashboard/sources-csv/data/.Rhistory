group_by(date) %>%
summarize(deaths = sum(entries, na.rm = TRUE))
if (daily_or_weekly == 'daily'){
deaths <- mutate(deaths, date = as.Date(date))
}
#' infections_14_days_ago <- bern_data_cases %>%
#' mutate(date = as.Date(datum)) %>%
#' mutate(infections_14_days_ago = lag(entries, 14, default = 0)) %>%
#' select(date, infections_14_days_ago)
#' recovered_per_day <- infections_14_days_ago %>%
#' mutate(recovered_per_day = pmax(0, infections_14_days_ago - deaths$deaths)) %>%
#' select(date, recovered_per_day)
if (daily_or_weekly == 'daily'){
dates <- seq(as.Date("2020-02-24"), as.Date("2023-01-01"), by = "day")
} else {
dates <- cases$date
}
susceptibles_vector <- numeric(length(dates))
susceptibles_vector[1] <- population
for (i in 2:length(dates)) {
cases_by_date <- filter(cases, date == as.character(dates[i]))
if (nrow(cases_by_date) > 0) {
cases_by_date <- cases_by_date$cases[1]
susceptibles_vector[i] <- susceptibles_vector[i-1] - cases_by_date
} else {
susceptibles_vector[i] <- susceptibles_vector[i-1]
}
}
susceptibles <- data.frame(date = dates, susceptibles = susceptibles_vector)
observations <- left_join(susceptibles, cases, by = "date") %>%
#left_join(recovered_per_day, by = "date") %>%
left_join(deaths, by = "date")
observations$deaths[is.na(observations$deaths)] <- 0
colnames(observations) <- c('date','S','I','D')
n <- nrow(observations) # size of data_grid
################################
####### TRAIN/VAL SETS #########
################################
#' Train and validation sets.
#' set.seed(123)
#' indices <- seq_len(n)
#' train_indices <- sample(indices, size = 0.8 * n, replace = FALSE)
#' train_set <- observations[train_indices, ]
#' validation_set <- observations[-train_indices, ]
################################
######## SAVE THE DATA #########
################################
if (type == 'simulated') {
save(observations_simulate, file = file.path(directory, "simulated_data.Rdata"))
saveRDS(population_simulate, file = file.path(directory, "simulated_pop.Rds"))
saveRDS(real_beta, file = file.path(directory, "simulated_real_beta.Rds"))
} else {
region_filename <- paste0("real_data_", region, "_", daily_or_weekly, ".Rdata")
population_filename <- paste0("real_pop_", region, "_", daily_or_weekly, ".Rds")
save(observations, file = file.path(directory, region_filename))
saveRDS(population, file = file.path(directory, population_filename))
}
#################################### PROBODER ##################################
################################ Claire Descombes ##############################
###################################### Data ####################################
directory <- "~/Documents/GitHub/proboder/Data" # directory for data
type <- 'real' # set 'real' for real data, 'simulated' for simulated data
region <- 'BE' # 'BE' or 'GE' available (if 'real' data selected)
daily_or_weekly <- 'daily' # choose either 'daily' or 'weekly' (if 'real' data selected)
################################
####### SIMULATED DATA #########
################################
library(HETTMO)
params_unstratified = set_parameters()
params_unstratified$p_detect1 <- 1
params_unstratified$p_detect2 <- 1
population_simulate <- params_unstratified$popsize
simulate <- simulate_data(params = params_unstratified, ts = 1:45)
I <- simulate[[1]]
S <- rep(0,length(I))
for (i in 1:length(I)){
S[i] <- population_simulate - sum(I[1:i])
}
R <- simulate[[6]]
real_beta <- simulate[[3]]
date <- 1:length(S)
observations_simulate <- data.frame(date,S,I,R)
################################
########## REAL DATA ###########
################################
# Import dataset.
setwd("~/Documents/GitHub/proboder/data_covid_dashboard/sources-csv/data")
if (daily_or_weekly == 'daily'){
csv_data_cases <- read.csv(file = "COVID19Cases_geoRegion.csv")
csv_data_death <- read.csv(file = "COVID19Death_geoRegion.csv")
} else {
csv_data_cases <- read.csv(file = "COVID19Cases_geoRegion_w.csv")
csv_data_death <- read.csv(file = "COVID19Death_geoRegion_w.csv")
}
#'library(rjson)
#'library(jsonlite)
#'setwd("~/Nextcloud/Documents/Mathe/HS23/Master thesis/data_covid_dashboard/sources-json/data")
#'json_data <- fromJSON(file = "COVID19Cases_geoRegion_w.json")
#'json_dataframe <- as.data.frame(json_data)
# Data selection.
library(dplyr)
# Total population (Bern or Geneva, 2021).
if(region == 'BE'){
population <-  1047473
}else if(region == 'GE'){
population <- 511921
}else{
print('Invalid region!')
}
data_cases <- csv_data_cases %>%
filter(geoRegion == region)
data_death <- csv_data_death %>%
filter(geoRegion == region)
cases <- data_cases %>%
rename(date = datum) %>%
group_by(date) %>%
summarize(cases = sum(entries, na.rm = TRUE))
if (daily_or_weekly == 'daily'){
cases <- mutate(cases, date = as.Date(date))
}
deaths <- data_death %>%
rename(date = datum) %>%
group_by(date) %>%
summarize(deaths = sum(entries, na.rm = TRUE))
if (daily_or_weekly == 'daily'){
deaths <- mutate(deaths, date = as.Date(date))
}
#' infections_14_days_ago <- bern_data_cases %>%
#' mutate(date = as.Date(datum)) %>%
#' mutate(infections_14_days_ago = lag(entries, 14, default = 0)) %>%
#' select(date, infections_14_days_ago)
#' recovered_per_day <- infections_14_days_ago %>%
#' mutate(recovered_per_day = pmax(0, infections_14_days_ago - deaths$deaths)) %>%
#' select(date, recovered_per_day)
if (daily_or_weekly == 'daily'){
dates <- seq(as.Date("2020-02-24"), as.Date("2023-01-01"), by = "day")
} else {
dates <- cases$date
}
susceptibles_vector <- numeric(length(dates))
susceptibles_vector[1] <- population
for (i in 2:length(dates)) {
cases_by_date <- filter(cases, date == as.character(dates[i]))
if (nrow(cases_by_date) > 0) {
cases_by_date <- cases_by_date$cases[1]
susceptibles_vector[i] <- susceptibles_vector[i-1] - cases_by_date
} else {
susceptibles_vector[i] <- susceptibles_vector[i-1]
}
}
susceptibles <- data.frame(date = dates, susceptibles = susceptibles_vector)
observations <- left_join(susceptibles, cases, by = "date") %>%
#left_join(recovered_per_day, by = "date") %>%
left_join(deaths, by = "date")
observations$deaths[is.na(observations$deaths)] <- 0
colnames(observations) <- c('date','S','I','D')
n <- nrow(observations) # size of data_grid
################################
####### TRAIN/VAL SETS #########
################################
#' Train and validation sets.
#' set.seed(123)
#' indices <- seq_len(n)
#' train_indices <- sample(indices, size = 0.8 * n, replace = FALSE)
#' train_set <- observations[train_indices, ]
#' validation_set <- observations[-train_indices, ]
################################
######## SAVE THE DATA #########
################################
if (type == 'simulated') {
save(observations_simulate, file = file.path(directory, "simulated_data.Rdata"))
saveRDS(population_simulate, file = file.path(directory, "simulated_pop.Rds"))
saveRDS(real_beta, file = file.path(directory, "simulated_real_beta.Rds"))
} else {
region_filename <- paste0("real_data_", region, "_", daily_or_weekly, ".Rdata")
population_filename <- paste0("real_pop_", region, "_", daily_or_weekly, ".Rds")
save(observations, file = file.path(directory, region_filename))
saveRDS(population, file = file.path(directory, population_filename))
}
#################################### PROBODER ##################################
################################ Claire Descombes ##############################
###################################### Data ####################################
directory <- "~/Documents/GitHub/proboder/Data" # directory for data
type <- 'real' # set 'real' for real data, 'simulated' for simulated data
region <- 'GE' # 'BE' or 'GE' available (if 'real' data selected)
daily_or_weekly <- 'daily' # choose either 'daily' or 'weekly' (if 'real' data selected)
################################
####### SIMULATED DATA #########
################################
library(HETTMO)
params_unstratified = set_parameters()
params_unstratified$p_detect1 <- 1
params_unstratified$p_detect2 <- 1
population_simulate <- params_unstratified$popsize
simulate <- simulate_data(params = params_unstratified, ts = 1:45)
I <- simulate[[1]]
S <- rep(0,length(I))
for (i in 1:length(I)){
S[i] <- population_simulate - sum(I[1:i])
}
R <- simulate[[6]]
real_beta <- simulate[[3]]
date <- 1:length(S)
observations_simulate <- data.frame(date,S,I,R)
################################
########## REAL DATA ###########
################################
# Import dataset.
setwd("~/Documents/GitHub/proboder/data_covid_dashboard/sources-csv/data")
if (daily_or_weekly == 'daily'){
csv_data_cases <- read.csv(file = "COVID19Cases_geoRegion.csv")
csv_data_death <- read.csv(file = "COVID19Death_geoRegion.csv")
} else {
csv_data_cases <- read.csv(file = "COVID19Cases_geoRegion_w.csv")
csv_data_death <- read.csv(file = "COVID19Death_geoRegion_w.csv")
}
#'library(rjson)
#'library(jsonlite)
#'setwd("~/Nextcloud/Documents/Mathe/HS23/Master thesis/data_covid_dashboard/sources-json/data")
#'json_data <- fromJSON(file = "COVID19Cases_geoRegion_w.json")
#'json_dataframe <- as.data.frame(json_data)
# Data selection.
library(dplyr)
# Total population (Bern or Geneva, 2021).
if(region == 'BE'){
population <-  1047473
}else if(region == 'GE'){
population <- 511921
}else{
print('Invalid region!')
}
data_cases <- csv_data_cases %>%
filter(geoRegion == region)
data_death <- csv_data_death %>%
filter(geoRegion == region)
cases <- data_cases %>%
rename(date = datum) %>%
group_by(date) %>%
summarize(cases = sum(entries, na.rm = TRUE))
if (daily_or_weekly == 'daily'){
cases <- mutate(cases, date = as.Date(date))
}
deaths <- data_death %>%
rename(date = datum) %>%
group_by(date) %>%
summarize(deaths = sum(entries, na.rm = TRUE))
if (daily_or_weekly == 'daily'){
deaths <- mutate(deaths, date = as.Date(date))
}
#' infections_14_days_ago <- bern_data_cases %>%
#' mutate(date = as.Date(datum)) %>%
#' mutate(infections_14_days_ago = lag(entries, 14, default = 0)) %>%
#' select(date, infections_14_days_ago)
#' recovered_per_day <- infections_14_days_ago %>%
#' mutate(recovered_per_day = pmax(0, infections_14_days_ago - deaths$deaths)) %>%
#' select(date, recovered_per_day)
if (daily_or_weekly == 'daily'){
dates <- seq(as.Date("2020-02-24"), as.Date("2023-01-01"), by = "day")
} else {
dates <- cases$date
}
susceptibles_vector <- numeric(length(dates))
susceptibles_vector[1] <- population
for (i in 2:length(dates)) {
cases_by_date <- filter(cases, date == as.character(dates[i]))
if (nrow(cases_by_date) > 0) {
cases_by_date <- cases_by_date$cases[1]
susceptibles_vector[i] <- susceptibles_vector[i-1] - cases_by_date
} else {
susceptibles_vector[i] <- susceptibles_vector[i-1]
}
}
susceptibles <- data.frame(date = dates, susceptibles = susceptibles_vector)
observations <- left_join(susceptibles, cases, by = "date") %>%
#left_join(recovered_per_day, by = "date") %>%
left_join(deaths, by = "date")
observations$deaths[is.na(observations$deaths)] <- 0
colnames(observations) <- c('date','S','I','D')
n <- nrow(observations) # size of data_grid
################################
####### TRAIN/VAL SETS #########
################################
#' Train and validation sets.
#' set.seed(123)
#' indices <- seq_len(n)
#' train_indices <- sample(indices, size = 0.8 * n, replace = FALSE)
#' train_set <- observations[train_indices, ]
#' validation_set <- observations[-train_indices, ]
################################
######## SAVE THE DATA #########
################################
if (type == 'simulated') {
save(observations_simulate, file = file.path(directory, "simulated_data.Rdata"))
saveRDS(population_simulate, file = file.path(directory, "simulated_pop.Rds"))
saveRDS(real_beta, file = file.path(directory, "simulated_real_beta.Rds"))
} else {
region_filename <- paste0("real_data_", region, "_", daily_or_weekly, ".Rdata")
population_filename <- paste0("real_pop_", region, "_", daily_or_weekly, ".Rds")
save(observations, file = file.path(directory, region_filename))
saveRDS(population, file = file.path(directory, population_filename))
}
library(matrixcalc)
# Import data (in case 'real': date-S-I-D, in case 'simulated': date-S-I-R).
directory_data <- "~/Documents/GitHub/proboder/Data" # directory of data
type <- 'real' # set 'real' for real data, 'simulated' for simulated data
region <- 'BE' # 'BE' or 'GE' available (if 'real' data selected)
daily_or_weekly <- 'weekly' # choose either 'daily' or 'weekly' (if 'real' data selected)
data <- load_data(type,region,daily_or_weekly,directory_data)
obs <- data$observations
pop <- data$population
real_beta <- data$real_beta
# Sanity check.
head(obs)
# Observation matrix (for observation of S,I and D)
if(type == 'real'){
H <- as.matrix(sparseMatrix(i = c(1,2,3), j = c(1,2,4), x = 1, dims = c(3,14)))
}else if(type == 'simulated'){
H <- as.matrix(sparseMatrix(i = c(1,2,3), j = c(1,2,3), x = 1, dims = c(3,14)))
}else{
print('Wrong type!')
}
# Import data (in case 'real': date-S-I-D, in case 'simulated': date-S-I-R).
directory_data <- "~/Documents/GitHub/proboder/Data" # directory of data
type <- 'simulated' # set 'real' for real data, 'simulated' for simulated data
region <- 'BE' # 'BE' or 'GE' available (if 'real' data selected)
daily_or_weekly <- 'weekly' # choose either 'daily' or 'weekly' (if 'real' data selected)
data <- load_data(type,region,daily_or_weekly,directory_data)
obs <- data$observations
pop <- data$population
real_beta <- data$real_beta
# Sanity check.
head(obs)
summary(obs)
# Initialize solution of SIRD-ODE and its two first derivatives
X <- as.vector(c(data= c(obs[1,2],rep(0,11))))
# Initialize latent parameter (contact rate) and its first derivative
U <- as.vector(c(0,0))
# Fixed parameters
gamma <- 0.06  # Recovery rate
eta <- 0.002   # Fatality rate
l <- 14        # Length scale
# Drift matrices
F_U <- matrix(c(0,-(sqrt(3)/l)^2,1,-2*sqrt(3)/l), nrow = 2, ncol = 2)
F_X <- as.matrix(sparseMatrix(i = 1:8, j = 5:12, x = 1, dims = c(12,12)))
# Dispersion matrices
L_U <- matrix(c(0,1), nrow = 2, ncol = 1)
L_X <- as.matrix(sparseMatrix(i = 9:12, j = 1:4, x = 1, dims = c(12,4)))
# Observation matrix (for observation of S,I and D)
if(type == 'real'){
H <- as.matrix(sparseMatrix(i = c(1,2,3), j = c(1,2,4), x = 1, dims = c(3,14)))
}else if(type == 'simulated'){
H <- as.matrix(sparseMatrix(i = c(1,2,3), j = c(1,2,3), x = 1, dims = c(3,14)))
}else{
print('Wrong type!')
}
H
# Observation noise
R <- matrix(0.001, nrow = 3, ncol = 3)
# Noise of priors
P_X <- matrix(0.001, nrow = 12, ncol = 12)
P_U <- matrix(0.001, nrow = 2, ncol = 2)
# Data grid
data_grid <- obs[,'date']
# ODE grid
ode_grid <- data_grid # more points could be added
# Overall time grid
time_grid <- sort(unique(c(data_grid, ode_grid)))
# Arrays to store values
X_values <- matrix(data = NA, nrow = 12, ncol = length(time_grid))
U_values <- matrix(data = NA, nrow = 2, ncol = length(time_grid))
P_X_values <- array(data = NA, dim = c(12, 12, length(time_grid)))
P_U_values <- array(data = NA, dim = c(2, 2, length(time_grid)))
# Run inference.
for (loc in time_grid){
X_values[,loc] <- as.vector(X)
U_values[,loc] <- as.vector(U)
P_X_values[,,loc] <- as.matrix(P_X)
P_U_values[,,loc] <- as.matrix(P_U)
# Prediction step.
U <- as.vector(prediction_U(m_U=U,P_U=P_U,F_U=F_U,L_U=L_U)[[1]])
P_U <- as.matrix(prediction_U(m_U=U,P_U=P_U,F_U=F_U,L_U=L_U)[[2]])
X <- as.vector(prediction_X(m_X=X,P_X=P_X,F_X=F_X,L_X=L_X)[[1]])
P_X <- as.matrix(prediction_X(m_X=X,P_X=P_X,F_X=F_X,L_X=L_X)[[2]])
# Update of observations.
if (any(data_grid == loc)){
m <- as.vector(c(X,U))
P <- matrix_P(P_X,P_U)
y <- unlist(obs[which(obs[, 1] == loc),2:4])
X <- as.vector(update_of_observations(m,P,y,H,R)[[1]][1:12])
U <- as.vector(update_of_observations(m,P,y,H,R)[[1]][13:14])
P_X <- as.matrix(update_of_observations(m,P,y,H,R)[[2]][1:12,1:12])
P_U <- as.matrix(update_of_observations(m,P,y,H,R)[[2]][13:14,13:14])
}
# Update of states.
if (any(ode_grid == loc)){
P <- matrix_P(P_X,P_U)
J <- jacobian_h(X,U,pop,gamma,eta)
m <- c(X,U)
h_val <- h(X,U,pop,gamma,eta)
X <- as.vector(update_of_states(m,P,h_val,J)[[1]][1:12])
U <- as.vector(update_of_states(m,P,h_val,J)[[1]][13:14])
P_X <- as.matrix(update_of_states(m,P,h_val,J)[[2]][1:12,1:12])
P_U <- as.matrix(update_of_states(m,P,h_val,J)[[2]][13:14,13:14])
}
}
# Specify directory for results
directory_res = "~/Documents/GitHub/proboder/Results"
# Save results to the specified directory
save_matrices_as_Rdata(X_values, U_values, P_X_values, P_U_values, directory_res)
# Load and process data from the specified directory
processed_data <- load_and_process_data(directory_res,time_grid)
U_plot <- processed_data$U_plot
P_plot <- processed_data$P_plot
ymin <- P_plot$ymin
ymax <- P_plot$ymax
U_value <- processed_data$U_scaled
# Create data frame for real beta values (if available)
real_beta_df <- data.frame(time = time_grid, real_beta = real_beta)
# Plot contact rate
plot_contact_rate(type, U_plot, ymin, ymax, U_value, real_beta_df)
#################################### PROBODER ##################################
################################ Claire Descombes ##############################
########################## Saving, loading, plotting ###########################
load_data <- function(type, region, daily_or_weekly, directory) {
# Check if type is valid
if (!(type %in% c('simulated', 'real'))) {
stop("Error: Invalid type. Type must be 'simulated' or 'real'.")
}
# Check if region is valid
if (!(region %in% c('BE', 'GE'))) {
stop("Error: Invalid region. Region must be 'BE' or 'GE'.")
}
# Check if daily_or_weekly is valid
if (!(daily_or_weekly %in% c('daily', 'weekly'))) {
stop("Error: Invalid value for daily_or_weekly. Must be 'daily' or 'weekly'.")
}
# Load data based on type
if (type == 'simulated') {
load(file.path(directory, "simulated_data.Rdata"))
obs <- observations_simulate
population <- readRDS(file.path(directory, "simulated_pop.Rds"))
real_beta <- readRDS(file.path(directory, "simulated_real_beta.Rds"))
} else {
region_filename <- paste0("real_data_", region, "_", daily_or_weekly, ".Rdata")
population_filename <- paste0("real_pop_", region, "_", daily_or_weekly, ".Rds")
load(file.path(directory, region_filename))
obs <- observations
population <- readRDS(file.path(directory, population_filename))
real_beta <- NULL
}
# Return loaded data
return(list(observations = obs, population = population, real_beta = real_beta))
}
save_matrices_as_Rdata <- function(X_values, U_values, P_X_values, P_U_values, directory) {
# Save X_values, U_values, P_X_values, and P_U_values as .Rdata files
save(X_values, file = paste0(directory, "/X_values.Rdata"))
save(U_values, file = paste0(directory, "/U_values.Rdata"))
save(P_X_values, file = paste0(directory, "/P_X_values.Rdata"))
save(P_U_values, file = paste0(directory, "/P_U_values.Rdata"))
# Calculate sigmoid of U_values[1, ]
U_scaled <- round(sigmoid(U_values[1, ]),3)
# Save sigmoid of U_values[1, ] as CSV
U_scaled_df <- data.frame(U_scaled)
write.csv(U_scaled_df, file = paste0(directory, "/U_scaled.csv"), row.names = FALSE)
}
load_and_process_data <- function(directory_res, time_grid) {
# Load matrices from saved .Rdata files
load(file.path(directory_res, "X_values.Rdata"))
load(file.path(directory_res, "U_values.Rdata"))
load(file.path(directory_res, "P_X_values.Rdata"))
load(file.path(directory_res, "P_U_values.Rdata"))
# Process U_values for visualization
U_scaled <- sigmoid(U_values[1, ])
U_plot <- data.frame(time = time_grid, U_value = U_scaled, row.names = NULL)
# Process P_U_values for visualization
P_U_scaled <- P_U_scaled <- sqrt(P_U_values[1, 1, ])
ymin <- U_scaled - P_U_scaled
ymax <- U_scaled + P_U_scaled
# Create data frame for P_plot
P_plot <- data.frame(time = time_grid, ymin = ymin, ymax = ymax, row.names = NULL)
# Return processed data
return(list(U_plot = U_plot, P_plot = P_plot, U_scaled = U_scaled))
}
plot_contact_rate <- function(type, U_plot, ymin, ymax, U_value, real_beta_df=NULL) {
library(ggplot2)
if (type == 'simulated') {
ggplot() +
geom_line(data = U_plot, aes(x = time, y = U_value, color = "Estimated Contact Rate"), linewidth = 1) +
geom_ribbon(data = data.frame(time = U_plot$time, ymin = ymin, ymax = ymax), aes(x = time, ymin = ymin, ymax = ymax), fill = "lightgreen", alpha = 0.5) +
geom_line(data = real_beta_df, aes(x = time, y = real_beta, color = "Real Contact Rate"), linetype = "dashed") +
labs(x = "Time", y = "Contact rate", title = "Contact rate with Error Area",
color = "Legend") +
scale_color_manual(values = c("Estimated Contact Rate" = "darkgreen", "Real Contact Rate" = "lightblue4"),
labels = c("Estimated Contact Rate", "Real Contact Rate")) +
coord_cartesian(ylim = c(-1, 2)) +
theme_minimal() +
theme(legend.position = "top")
} else {
ggplot() +
geom_line(data = U_plot, aes(x = time, y = U_value, color = "Estimated Contact Rate"), linewidth = 1) +
geom_ribbon(data = data.frame(time = U_plot$time, ymin = ymin, ymax = ymax), aes(x = time, ymin = ymin, ymax = ymax), fill = "lightgreen", alpha = 0.5) +
labs(x = "Time", y = "Contact rate", title = "Contact rate with Error Area",
color = "Legend") +
scale_color_manual(values = c("Estimated Contact Rate" = "darkgreen"),
labels = "Estimated Contact Rate") +
coord_cartesian(ylim = c(-1, 2)) +
theme_minimal() +
theme(legend.position = "top")
}
}
# Plot contact rate
plot_contact_rate(type, U_plot, ymin, ymax, U_value, real_beta_df)
