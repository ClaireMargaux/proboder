}else if(type == 'simulated_LSODA_sin'){
initial_params <-
initialization(obs_with_noise, beta0 = real_beta[1], beta0prime = 0.1,
lambda = params$lambda, gamma = params$gamma, eta = params$eta,
l = 13.5, scale = 1, noise_obs = params$obs_noise,
noise_X = sqrt(params$obs_noise), noise_U = 0.01,
noise_wiener_X = 0.01, noise_wiener_U = 0.001,
pop = params$pop,
num_points_between = 0)
}else if(type == 'simulated_LSODA_log'){
initial_params <-
initialization(obs_with_noise, beta0 = real_beta[1], beta0prime = 0.1,
lambda = params$lambda, gamma = params$gamma, eta = params$eta,
l = 10, scale = 1, noise_obs = params$obs_noise,
noise_X = 0.001, noise_U = 0.01,
noise_wiener_X = 100, noise_wiener_U = 0.05,
pop = params$pop,
num_points_between = 0)
}
# If using data simulated with HETTMO:
# initial_params <-
#   initialization(obs, beta0 = 0.9721224, beta0prime = -1.5,
#                  lambda = 0.3703704, gamma = 0.3703704, eta = 0,
#                  l = 1.2, scale = 3, noise_obs = 100,
#                  noise_wiener_X = 1e+03, noise_wiener_U = 0.1,
#                  pop = 1e+05)
#####################################
############# INFERENCE #############
#####################################
# Data grid
data_grid <- obs[,'t']
# ODE grid
ode_grid <- data_grid # no more points than observations
# Adding more points than observations
for (i in 1:(length(data_grid) - 1)) {
# Generate equidistant points between the current and next data point
equidistant_points <- seq(data_grid[i], data_grid[i + 1], length.out = initial_params$num_points_between + 2)[-c(1, initial_params$num_points_between + 2)]
# Append the equidistant points to the ODE grid
ode_grid <- c(ode_grid, equidistant_points)
ode_grid <- sort(ode_grid)
}
# Overall time grid
time_grid <- sort(unique(c(data_grid, ode_grid)))
# Time steps
steps <- ode_grid[2]-ode_grid[1]
# Run inference
inference_results <- inference(time_grid, data_grid, ode_grid, steps, obs, initial_params)
X_values <- inference_results$X_values
U_values <- inference_results$U_values
P_X_values <- inference_results$P_X_values
P_U_values <- inference_results$P_U_values
# ------------
# Save results
# ------------
# Specify directory for results
if(type == 'simulated_LSODA_sin'){
directory_res <- "~/Documents/GitHub/proboder/Results/sin" # directory of data
}else if(type == 'simulated_LSODA_log'){
directory_res <- "~/Documents/GitHub/proboder/Results/log" # directory of data
}else if(type == 'simulated_HETTMO'){
directory_res <- "~/Documents/GitHub/proboder/Results/hettmo" # directory of data
}
# Save results to the specified directory
save_results_as_Rdata(X_values, U_values, P_X_values, P_U_values, directory_res)
###############################
########### SCORING ###########
###############################
# ---------------------
# Extract relevant data
# ---------------------
# Load and process data from the specified directory
processed_data <- load_and_process_data(directory_res,time_grid)
U_plot <- processed_data$U_plot
X_plot <- processed_data$X_plot
# Save processed data to the specified directory
save_processed_data(U_plot, X_plot, directory_res)
# Create data frame for real beta values
real_beta_df <- data.frame(time = data_grid, real_beta = real_beta)
colnames(real_beta_df) <- c('t','beta')
# --------
# Scoring
# --------
# Compute the different scores
SPE <- squared_prediction_error(U_plot,real_beta_df)
NLPD <-negative_log_predictive_density(U_plot,real_beta_df)
CRPS <- continuous_ranked_probability_score(U_plot,real_beta_df)
# Create a data frame with the results
results <- data.frame(
Method = c("Squared Prediction Error", "Negative Log Predictive Density", "Continuous Ranked Probability Score"),
Value = c(SPE, NLPD, CRPS)
)
# # Create nice table using knitr and kableExtra
table <- kable(results, align = "c", caption = "Scoring Methods Results")
(styled_table <- kableExtra::kable_styling(table, bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE))
# ------
# Saving
# ------
# Save the table as a HTML file
file_path_html <- file.path(directory_res, "scoring_results.html")
save_kable(styled_table, file = file_path_html, type = "html")
# To store the table as a png file, use the manual export option from the viewer.
# Save in size 400x200.
#####################################
########### VISUALIZATION ###########
#####################################
# --------
# Plotting
# --------
# Plot simulated compartment counts and noisy simulated observations.
file_path <- file.path(directory_res, "sim-counts.pdf")
pdf(file_path, width = 8, height = 6)
plot_sim(obs, obs_with_noise)
dev.off()
plot_sim(obs, obs_with_noise)
# Plot compartment counts inferred from simulated data
file_path <- file.path(directory_res, "SEIRD-counts.pdf")
pdf(file_path, width = 10, height = 6)
plot_data_sim(obs,obs_with_noise,X_plot)
dev.off()
plot_data_sim(obs,obs_with_noise,X_plot)
# Plot compartment counts separately
plots <- plot_compartment(obs,obs_with_noise,X_plot)
for (i in 1:5) {
file_path <- file.path(directory_res, paste0("SEIRD-counts-sep-with-CI-", i, ".pdf"))
pdf(file_path, width = 8, height = 6)
plot <- plots[[i]]
print(plot)
dev.off()
}
for (i in 1:5) {
plot <- plots[[i]]
print(plot)
}
# Get some fixed values to plot together with contact rate
lambda <- initial_params$lambda
gamma <- initial_params$gamma
eta <- initial_params$eta
l <- initial_params$l
# Plot simulated contact rate
file_path <- file.path(directory_res, "sim-contact-rate.pdf")
pdf(file_path, width = 8, height = 6)
plot_sim_contact_rate(real_beta_df, lambda, gamma, eta)
dev.off()
plot_sim_contact_rate(real_beta_df, lambda, gamma, eta)
# Plot contact rate inferred from simulated data
file_path <- file.path(directory_res, "inf-contact-rate-with-CI.pdf")
pdf(file_path, width = 10, height = 6)
plot_contact_rate_with_CI(U_plot, real_beta_df, lambda, gamma, eta, l)
dev.off()
plot_contact_rate_with_CI(U_plot, real_beta_df, lambda, gamma, eta, l)
# ------------
# Benchmarking
# ------------
# Total computation time
toc()
best_params
# Assumptions
incubation_period <- 5  # Days from S to E
infectious_period <- 10  # Days from E to I
directory <- "~/home/claire/Documents/data_covid_dashboard/sources-csv/data" # directory of data
region <- 'GE' # 'BE' or 'GE' available (if 'real' data selected)
daily_or_weekly <- 'weekly' # choose either 'daily' or 'weekly' (if 'real' data selected)
# Assumptions
incubation_period <- 5  # Days from S to E
infectious_period <- 10  # Days from E to I
# Import dataset.
setwd("~/Documents/GitHub/proboder/data_covid_dashboard/sources-csv/data")
if (daily_or_weekly == 'daily'){
csv_data_cases <- read.csv(file = "COVID19Cases_geoRegion.csv")
csv_data_death <- read.csv(file = "COVID19Death_geoRegion.csv")
} else {
csv_data_cases <- read.csv(file = "COVID19Cases_geoRegion_w.csv")
csv_data_death <- read.csv(file = "COVID19Death_geoRegion_w.csv")
}
# Data selection.
library(dplyr)
# Total population (Bern or Geneva, 2021).
if(region == 'BE'){
population <-  1047473
}else if(region == 'GE'){
population <- 511921
}else{
print('Invalid region!')
}
data_cases <- csv_data_cases %>%
filter(geoRegion == region)
data_death <- csv_data_death %>%
filter(geoRegion == region)
cases <- data_cases %>%
rename(date = datum) %>%
group_by(date) %>%
summarize(cases = sum(entries, na.rm = TRUE)) %>%
arrange(date) %>%
mutate(cases = cumsum(cases))
if (daily_or_weekly == 'daily'){
cases <- mutate(cases, date = as.Date(date))
}
deaths <- data_death %>%
rename(date = datum) %>%
mutate(cumulative_entries = cumsum(entries)) %>%
group_by(date) %>%
summarize(deaths = sum(cumulative_entries, na.rm = TRUE))
if (daily_or_weekly == 'daily'){
deaths <- mutate(deaths, date = as.Date(date))
}
if (daily_or_weekly == 'daily'){
dates <- seq(as.Date("2020-02-24"), as.Date("2023-01-01"), by = "day")
} else {
dates <- cases$date
}
observations <- inner_join(cases, deaths, by = "date")
observations$deaths[is.na(observations$deaths)] <- 0
colnames(observations) <- c('t','R','D')
observations
# Initialize compartments
S <- numeric(length(dates))
E <- numeric(length(dates))
I <- numeric(length(dates))
# Loop through dates
for (i in 1:length(t)) {
date <- t[i]
# Calculate new infections that happened incubation_period days ago
if (i > incubation_period) {
new_infections <- S[i - incubation_period] - S[i - incubation_period - 1]
} else {
new_infections <- 0
}
# Update compartments S, E, I
if (i > infectious_period) {
S[i] <- S[i - 1] - new_infections
E[i] <- E[i - 1] + new_infections - (I[i - infectious_period] - I[i - infectious_period - 1])
I[i] <- I[i - 1] + (I[i - infectious_period] - I[i - infectious_period - 1])
} else {
S[i] <- S[i - 1] - new_infections
E[i] <- E[i - 1] + new_infections
I[i] <- I[i - 1]
}
# Ensure non-negative counts
S[i] <- max(0, S[i])
E[i] <- max(0, E[i])
I[i] <- max(0, I[i])
}
length(t)
observations
# Initialize compartments
S <- numeric(length(dates))
E <- numeric(length(dates))
I <- numeric(length(dates))
dates
if (daily_or_weekly == 'daily'){
dates <- seq(as.Date("2020-02-24"), as.Date("2023-01-01"), by = "day")
} else {
dates <- cases$date
}
observations <- inner_join(cases, deaths, by = "date")
observations$deaths[is.na(observations$deaths)] <- 0
colnames(observations) <- c('t','R','D')
observations
directory <- "~/home/claire/Documents/data_covid_dashboard/sources-csv/data" # directory of data
region <- 'GE' # 'BE' or 'GE' available (if 'real' data selected)
daily_or_weekly <- 'daily' # choose either 'daily' or 'weekly' (if 'real' data selected)
# Assumptions
incubation_period <- 5  # Days from S to E
infectious_period <- 10  # Days from E to I
# Import dataset.
setwd("~/Documents/GitHub/proboder/data_covid_dashboard/sources-csv/data")
if (daily_or_weekly == 'daily'){
csv_data_cases <- read.csv(file = "COVID19Cases_geoRegion.csv")
csv_data_death <- read.csv(file = "COVID19Death_geoRegion.csv")
} else {
csv_data_cases <- read.csv(file = "COVID19Cases_geoRegion_w.csv")
csv_data_death <- read.csv(file = "COVID19Death_geoRegion_w.csv")
}
# Data selection.
library(dplyr)
# Total population (Bern or Geneva, 2021).
if(region == 'BE'){
population <-  1047473
}else if(region == 'GE'){
population <- 511921
}else{
print('Invalid region!')
}
data_cases <- csv_data_cases %>%
filter(geoRegion == region)
data_death <- csv_data_death %>%
filter(geoRegion == region)
cases <- data_cases %>%
rename(date = datum) %>%
group_by(date) %>%
summarize(cases = sum(entries, na.rm = TRUE)) %>%
arrange(date) %>%
mutate(cases = cumsum(cases))
if (daily_or_weekly == 'daily'){
cases <- mutate(cases, date = as.Date(date))
}
deaths <- data_death %>%
rename(date = datum) %>%
mutate(cumulative_entries = cumsum(entries)) %>%
group_by(date) %>%
summarize(deaths = sum(cumulative_entries, na.rm = TRUE))
if (daily_or_weekly == 'daily'){
deaths <- mutate(deaths, date = as.Date(date))
}
if (daily_or_weekly == 'daily'){
dates <- seq(as.Date("2020-02-24"), as.Date("2023-01-01"), by = "day")
} else {
dates <- cases$date
}
observations <- inner_join(cases, deaths, by = "date")
observations$deaths[is.na(observations$deaths)] <- 0
colnames(observations) <- c('t','R','D')
observations
dates
# Initialize compartments
S <- numeric(length(dates))
E <- numeric(length(dates))
I <- numeric(length(dates))
# Loop through dates
for (i in 1:length(dates)) {
date <- dates[i]
# Calculate new infections that happened incubation_period days ago
if (i > incubation_period) {
new_infections <- S[i - incubation_period] - S[i - incubation_period - 1]
} else {
new_infections <- 0
}
# Update compartments S, E, I
if (i > infectious_period) {
S[i] <- S[i - 1] - new_infections
E[i] <- E[i - 1] + new_infections - (I[i - infectious_period] - I[i - infectious_period - 1])
I[i] <- I[i - 1] + (I[i - infectious_period] - I[i - infectious_period - 1])
} else {
S[i] <- S[i - 1] - new_infections
E[i] <- E[i - 1] + new_infections
I[i] <- I[i - 1]
}
# Ensure non-negative counts
S[i] <- max(0, S[i])
E[i] <- max(0, E[i])
I[i] <- max(0, I[i])
}
observations
observations[1,1]
observations[1,1]-1
date <- dates[1]
date
i > incubation_period
num_dates <- length(dates)
# Initialize compartments
num_dates <- length(dates)
S <- numeric(num_dates)
E <- numeric(num_dates)
I <- numeric(num_dates)
num_dates:1
# Backward computation
for (i in num_dates:1) {
# Calculate new infections (I)
if (i + infectious_period <= num_dates) {
new_infections <- R[i + infectious_period] - R[i + infectious_period - 1]
} else {
new_infections <- 0
}
# Calculate new exposures (E)
if (i + incubation_period <= num_dates) {
new_exposures <- I[i + incubation_period] - I[i + incubation_period - 1] + new_infections
} else {
new_exposures <- new_infections
}
# Update compartments
if (i == num_dates) {
I[i] <- new_infections
E[i] <- new_exposures
S[i] <- population
} else {
I[i] <- I[i + 1] + new_infections
E[i] <- E[i + 1] + new_exposures
S[i] <- S[i + 1] + new_exposures
}
# Ensure non-negative counts
S[i] <- max(0, S[i])
E[i] <- max(0, E[i])
I[i] <- max(0, I[i])
}
# Backward computation
for (i in num_dates:1) {
# Calculate new infections (I)
if (i + infectious_period <= num_dates) {
new_infections <- observations$R[i + infectious_period] - observations$R[i + infectious_period - 1]
} else {
new_infections <- 0
}
# Calculate new exposures (E)
if (i + incubation_period <= num_dates) {
new_exposures <- observations$I[i + incubation_period] - observations$I[i + incubation_period - 1] + new_infections
} else {
new_exposures <- new_infections
}
# Update compartments
if (i == num_dates) {
I[i] <- new_infections
E[i] <- new_exposures
S[i] <- population
} else {
I[i] <- I[i + 1] + new_infections
E[i] <- E[i + 1] + new_exposures
S[i] <- S[i + 1] + new_exposures
}
# Ensure non-negative counts
S[i] <- max(0, S[i])
E[i] <- max(0, E[i])
I[i] <- max(0, I[i])
}
# Backward computation
for (i in num_dates:1) {
# Calculate new infections (I)
if (i + infectious_period <= num_dates) {
new_infections <- observations$R[i + infectious_period] - observations$R[i + infectious_period - 1]
} else {
new_infections <- 0
}
# Calculate new exposures (E)
if (i + incubation_period <= num_dates) {
new_exposures <- I[i + incubation_period] - I[i + incubation_period - 1] + new_infections
} else {
new_exposures <- new_infections
}
# Update compartments
if (i == num_dates) {
I[i] <- new_infections
E[i] <- new_exposures
S[i] <- population
} else {
I[i] <- I[i + 1] + new_infections
E[i] <- E[i + 1] + new_exposures
S[i] <- S[i + 1] + new_exposures
}
# Ensure non-negative counts
S[i] <- max(0, S[i])
E[i] <- max(0, E[i])
I[i] <- max(0, I[i])
}
# Create dataframe for S, E, I compartments
compartments <- data.frame(
date = dates,
S = S,
E = E,
I = I,
R = R,
D = D
)
# Create dataframe for S, E, I compartments
compartments <- data.frame(
date = observations$t,
S = S,
E = E,
I = I,
R = observations$R,
D = observations$D
)
compartments
total_removed <- observations$R + observations$D
total_removed
# Initialize compartments
num_dates <- length(dates)
S <- numeric(num_dates)
E <- numeric(num_dates)
I <- numeric(num_dates)
total_removed <- observations$R + observations$D
# Backward computation
for (i in num_dates:1) {
# Calculate new infections (I)
if (i + infectious_period <= num_dates) {
new_infections <- total_removed[i + infectious_period] - total_removed[i + infectious_period - 1]
} else {
new_infections <- 0
}
# Calculate new exposures (E)
if (i + incubation_period <= num_dates) {
new_exposures <- I[i + incubation_period] - I[i + incubation_period - 1] + new_infections
} else {
new_exposures <- new_infections
}
# Update compartments
if (i == num_dates) {
I[i] <- new_infections
E[i] <- new_exposures
S[i] <- population
} else {
I[i] <- I[i + 1] + new_infections
E[i] <- E[i + 1] + new_exposures
S[i] <- S[i + 1] + new_exposures
}
# Ensure non-negative counts
S[i] <- max(0, S[i])
E[i] <- max(0, E[i])
I[i] <- max(0, I[i])
}
# Create dataframe for S, E, I compartments
compartments <- data.frame(
date = observations$t,
S = S,
E = E,
I = I,
R = observations$R,
D = observations$D
)
compartments
158 + 277464 + 6154 + 289 + 512079
i <- num_dates
i
i + infectious_period <= num_dates
